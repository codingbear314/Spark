{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsEfeGzLviSq"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import torch\n",
        "from collections import deque\n",
        "\n",
        "def Load_Dataset():\n",
        "  dataset = []\n",
        "\n",
        "  company_list = [\n",
        "                    'AAPL',\n",
        "                    'GOOG',\n",
        "                    'NVDA',\n",
        "                    'TSLA',\n",
        "                    '005930.KS',\n",
        "                    '000660.KS',\n",
        "                    '035420.KS',\n",
        "                    '035720.KS',\n",
        "                    'MSFT',\n",
        "                    'GOOGL',\n",
        "                    'AMZN',\n",
        "                    'META',\n",
        "                    'AMD',\n",
        "                    'V',\n",
        "                    'BRK-B',\n",
        "                    'JNJ',\n",
        "                    'BABA',\n",
        "                    'TSM',\n",
        "                    'PG'\n",
        "                  ]\n",
        "\n",
        "  for company in company_list:\n",
        "      slidingWindow = deque()\n",
        "      ticker = yf.Ticker(company)\n",
        "      data = ticker.history(interval = '1d', period = 'max', auto_adjust = True)\n",
        "\n",
        "      Open = list(data['Open'])\n",
        "      Close = list(data['Close'])\n",
        "      High = list(data['High'])\n",
        "      Low = list(data['Low'])\n",
        "\n",
        "      if len(Open) < 61:\n",
        "          print(f\"{company} Doesn't have enough data!\")\n",
        "          continue\n",
        "      addindex = 61\n",
        "      for i in range(addindex):\n",
        "          slidingWindow.append(torch.tensor([Open[i], High[i], Low[i], Close[i]], dtype = torch.float64))\n",
        "      while addindex+1 < len(Open):\n",
        "          dataset.append(\n",
        "              (\n",
        "                  torch.stack(list(slidingWindow)[:-1]),\n",
        "                  list(slidingWindow)[-1]\n",
        "              )\n",
        "          )\n",
        "          addindex += 1\n",
        "          slidingWindow.append(torch.tensor([Open[addindex], High[addindex], Low[addindex], Close[addindex]], dtype = torch.float64))\n",
        "          slidingWindow.popleft()\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model structure\n",
        "\n",
        "* 60*4 input layer\n",
        "* Convolution layer (Conv2d, size of 8*4)\n",
        "* Convolution layer (Conv1d, size of 8)\n",
        "* Fully connected layer (Linear, size of 40)\n",
        "* Fully connected layer (Linear, size of 20)\n",
        "* Fully connected layer (Linear, size of 1)\n",
        "\n",
        "All activations ReLU"
      ],
      "metadata": {
        "id": "lSYtgvvf5kro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Finance_001_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Finance_001_Model, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=16, kernel_size=8)\n",
        "        conv1_out_side = 60 - 8 + 1\n",
        "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=8)\n",
        "        conv2_out_side = conv1_out_side - 8 + 1\n",
        "        self.dense1 = nn.Linear(32 * conv2_out_side, 40)\n",
        "        self.dense2 = nn.Linear(40, 20)\n",
        "        self.dense3 = nn.Linear(20, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.relu(self.conv1(x))\n",
        "      x = self.relu(self.conv2(x))\n",
        "      batch_size = x.size(0)\n",
        "      x = x.view(batch_size, -1)\n",
        "      x = self.relu(self.dense1(x))\n",
        "      x = self.relu(self.dense2(x))\n",
        "      x = self.dense3(x)\n",
        "      return x"
      ],
      "metadata": {
        "id": "1t5AAZ-O5ll7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loader"
      ],
      "metadata": {
        "id": "gri4PC7g5ql1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FinanceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.dataset[idx]"
      ],
      "metadata": {
        "id": "cffGOyYm5r49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the dataset"
      ],
      "metadata": {
        "id": "3HL2qS6o6XDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FinanceDataset = FinanceDataset(Load_Dataset())\n",
        "train_size = int(0.8 * len(FinanceDataset))\n",
        "validation_size = int(0.1 * len(FinanceDataset))\n",
        "test_size = len(FinanceDataset) - train_size - validation_size\n",
        "train_dataset, test_dataset, validation_dataset = torch.utils.data.random_split(FinanceDataset, [train_size, test_size, validation_size])\n",
        "\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Validation size: {len(validation_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")\n",
        "\n",
        "Train_Dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "Validation_Dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=32, shuffle=True)\n",
        "Test_Dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKsGPWNA65hi",
        "outputId": "98b8d355-b100-461d-e4e4-fdb2ca042338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 108816\n",
            "Validation size: 13602\n",
            "Test size: 13603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = Finance_001_Model().to(device)\n",
        "print(f\"Training on {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xty6m26P7cBz",
        "outputId": "2d5f18db-7f26-440c-db90-34f7d19ee317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "WdlOUEaO7jvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "2qIj_6x27s0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Train the model\n",
        "\n",
        "for epoch in range(100):\n",
        "  model.train()\n",
        "  for i, data in enumerate(Train_Dataloader):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss_value = loss(outputs, labels)\n",
        "    loss_value.backward()\n",
        "    optimizer.step()\n",
        "    if i % 100 == 0:\n",
        "      print(f\"Epoch: {epoch + 1}/{100}, Step: {i}, Loss: {loss_value.item():.4f}\")\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, data in enumerate(Validation_Dataloader):\n",
        "      inputs, labels = data[0].to(device), data[1].to(device)\n",
        "      outputs = model(inputs)\n",
        "      pred_y = torch.round(outputs)\n",
        "      correct += (pred_y == labels).sum().item()\n",
        "      total += len(labels)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch: {epoch + 1}/{100}, Accuracy: {accuracy:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ceDGkLU47uTx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}